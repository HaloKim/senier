{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pix2pix.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hrayqEs1EvG2","colab_type":"text"},"source":["# 구글드라이브 로드"]},{"cell_type":"code","metadata":{"id":"iwYKyf_v7SJD","colab_type":"code","outputId":"dc078ddc-04ce-4f78-eac6-dcbf7d8c8f33","executionInfo":{"status":"ok","timestamp":1576301641241,"user_tz":-540,"elapsed":19854,"user":{"displayName":"김광륜","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSwcYweAalXduuvjH1r9oJZt8MGaZqh-x0XppU=s64","userId":"15296129808647488288"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QwIHu6yQE4GI","colab_type":"text"},"source":["# 환경설정 keras-lib, requirements set"]},{"cell_type":"code","metadata":{"id":"Kx-Lhn2qYu2V","colab_type":"code","outputId":"b6c9ed48-8313-4f6a-9a29-5ce2657fe957","executionInfo":{"status":"ok","timestamp":1576301701928,"user_tz":-540,"elapsed":57664,"user":{"displayName":"김광륜","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSwcYweAalXduuvjH1r9oJZt8MGaZqh-x0XppU=s64","userId":"15296129808647488288"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#env settings\n","!pip install git+https://www.github.com/keras-team/keras-contrib.git\n","!pip install -r /content/drive/My\\ Drive/Colab\\ Notebooks/imports/requirements.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting git+https://www.github.com/keras-team/keras-contrib.git\n","  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-n5kvk3qb\n","  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-n5kvk3qb\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.3)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n","Building wheels for collected packages: keras-contrib\n","  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101065 sha256=7d77b81dcb4a35e8275d73c1a7c94cff80c8e7442013328dd6c6880d44dd5f77\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-54ry5w5o/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n","Successfully built keras-contrib\n","Installing collected packages: keras-contrib\n","Successfully installed keras-contrib-2.0.8\n","Collecting tensorflow==1.13.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n","\u001b[K     |████████████████████████████████| 92.5MB 89kB/s \n","\u001b[?25hCollecting pillow==6.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 31.0MB/s \n","\u001b[?25hCollecting numpy==1.16.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/41283370f942f647422581eed16df4b653a744a3e9d5cfbb9aee0440f6eb/numpy-1.16.5-cp36-cp36m-manylinux1_x86_64.whl (17.4MB)\n","\u001b[K     |████████████████████████████████| 17.4MB 503kB/s \n","\u001b[?25hCollecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 35.4MB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (0.8.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (3.10.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (0.33.6)\n","Collecting tensorboard<1.14.0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 36.3MB/s \n","\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 55.0MB/s \n","\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (1.0.8)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (0.2.2)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (0.8.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (42.0.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (0.16.0)\n","Collecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1->-r /content/drive/My Drive/Colab Notebooks/imports/requirements.txt (line 1)) (2.8.0)\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, tensorboard, mock, tensorflow-estimator, tensorflow, pillow, scipy\n","  Found existing installation: numpy 1.17.4\n","    Uninstalling numpy-1.17.4:\n","      Successfully uninstalled numpy-1.17.4\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","  Found existing installation: Pillow 4.3.0\n","    Uninstalling Pillow-4.3.0:\n","      Successfully uninstalled Pillow-4.3.0\n","  Found existing installation: scipy 1.3.3\n","    Uninstalling scipy-1.3.3:\n","      Successfully uninstalled scipy-1.3.3\n","Successfully installed mock-3.0.5 numpy-1.16.5 pillow-6.0.0 scipy-1.1.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZAKA_diqFCS7","colab_type":"text"},"source":["# main pix2pix train"]},{"cell_type":"markdown","metadata":{"id":"qfi5AEoVJSQR","colab_type":"text"},"source":["! 필요사항\n","data_loader.py upload\n","datasets.zip upload"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iajm4ccJblVg","outputId":"4438be76-01b9-43ca-fd46-e390d2067e7c","executionInfo":{"status":"ok","timestamp":1576306699297,"user_tz":-540,"elapsed":62605,"user":{"displayName":"김광륜","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSwcYweAalXduuvjH1r9oJZt8MGaZqh-x0XppU=s64","userId":"15296129808647488288"}},"colab":{"base_uri":"https://localhost:8080/","height":593}},"source":["from __future__ import print_function, division\n","from scipy.misc import imresize\n","\n","from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.models import model_from_json\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","from google.colab import drive, files\n","import datetime\n","import matplotlib.pyplot as plt\n","import sys\n","from data_loader import DataLoader\n","import numpy as np\n","import os\n","from glob import glob\n","\n","#! unzip /content/drive/My\\ Drive/Colab\\ Notebooks/imports/datasets.zip\n","#! unzip datasets.zip\n","\n","\n","# os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n","class Pix2Pix():\n","    def __init__(self):\n","        # Input shape\n","        self.img_rows = 256\n","        self.img_cols = 256\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        # Configure data loader\n","        self.dataset_name = 'tmp'\n","        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n","                                      img_res=(self.img_rows, self.img_cols))\n","\n","        # Calculate output shape of D (PatchGAN)\n","        patch = int(self.img_rows / 2 ** 4)\n","        self.disc_patch = (patch, patch, 1)\n","\n","        # Number of filters in the first layer of G and D\n","        self.gf = 64\n","        self.df = 64\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='mse',\n","                                   optimizer=optimizer,\n","                                   metrics=['accuracy'])\n","\n","        # -------------------------\n","        # Construct Computational\n","        #   Graph of Generator\n","        # -------------------------\n","\n","        # Build the generator\n","        self.generator = self.build_generator()\n","\n","        # Input images and their conditioning images\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # By conditioning on B generate a fake version of A\n","        fake_A = self.generator(img_B)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # Discriminators determines validity of translated images / condition pairs\n","        valid = self.discriminator([fake_A, img_B])\n","\n","        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, fake_A])\n","        self.combined.compile(loss=['mse', 'mae'],\n","                              loss_weights=[1, 100],\n","                              optimizer=optimizer)\n","\n","    def build_generator(self):\n","        \"\"\"U-Net Generator\"\"\"\n","\n","        def conv2d(layer_input, filters, f_size=4, bn=True):\n","            \"\"\"Layers used during downsampling\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if bn:\n","                d = BatchNormalization(momentum=0.8)(d)\n","            return d\n","\n","        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n","            \"\"\"Layers used during upsampling\"\"\"\n","            u = UpSampling2D(size=2)(layer_input)\n","            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","            if dropout_rate:\n","                u = Dropout(dropout_rate)(u)\n","            u = BatchNormalization(momentum=0.8)(u)\n","            u = Concatenate()([u, skip_input])\n","            return u\n","\n","        # Image input\n","        d0 = Input(shape=self.img_shape)\n","\n","        # Downsampling\n","        d1 = conv2d(d0, self.gf, bn=False)\n","        d2 = conv2d(d1, self.gf * 2)\n","        d3 = conv2d(d2, self.gf * 4)\n","        d4 = conv2d(d3, self.gf * 8)\n","        d5 = conv2d(d4, self.gf * 8)\n","        d6 = conv2d(d5, self.gf * 8)\n","        d7 = conv2d(d6, self.gf * 8)\n","\n","        # Upsampling\n","        u1 = deconv2d(d7, d6, self.gf * 8)\n","        u2 = deconv2d(u1, d5, self.gf * 8)\n","        u3 = deconv2d(u2, d4, self.gf * 8)\n","        u4 = deconv2d(u3, d3, self.gf * 4)\n","        u5 = deconv2d(u4, d2, self.gf * 2)\n","        u6 = deconv2d(u5, d1, self.gf)\n","\n","        u7 = UpSampling2D(size=2)(u6)\n","        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","        return Model(d0, output_img)\n","\n","    def build_discriminator(self):\n","\n","        def d_layer(layer_input, filters, f_size=4, bn=True):\n","            \"\"\"Discriminator layer\"\"\"\n","            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n","            d = LeakyReLU(alpha=0.2)(d)\n","            if bn:\n","                d = BatchNormalization(momentum=0.8)(d)\n","            return d\n","\n","        img_A = Input(shape=self.img_shape)\n","        img_B = Input(shape=self.img_shape)\n","\n","        # Concatenate image and conditioning image by channels to produce input\n","        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n","\n","        d1 = d_layer(combined_imgs, self.df, bn=False)\n","        d2 = d_layer(d1, self.df * 2)\n","        d3 = d_layer(d2, self.df * 4)\n","        d4 = d_layer(d3, self.df * 8)\n","\n","        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","        return Model([img_A, img_B], validity)\n","\n","    def train(self, epochs, batch_size=1, sample_interval=50):\n","        start_time = datetime.datetime.now()\n","\n","        # Adversarial loss ground truths\n","        valid = np.ones((batch_size,) + self.disc_patch)\n","        fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","        for epoch in range(epochs):\n","            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n","\n","                # ---------------------\n","                #  Train Discriminator\n","                # ---------------------\n","\n","                # Condition on B and generate a translated version\n","                fake_A = self.generator.predict(imgs_B)\n","\n","                # Train the discriminators (original images = real / generated = Fake)\n","                d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n","                d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n","                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","                # -----------------\n","                #  Train Generator\n","                # -----------------\n","\n","                # Train the generators\n","                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, imgs_A])\n","\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                # If at save interval => save generated image samples\n","                if batch_i % sample_interval == 0:\n","                    self.sample_images(epoch, batch_i)\n","\n","                # Plot the progress\n","                print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n","                                                                                                      batch_i,\n","                                                                                                      self.data_loader.n_batches,\n","                                                                                                      d_loss[0],\n","                                                                                                      100 * d_loss[1],\n","                                                                                                      g_loss[0],\n","                                                                                                      elapsed_time))\n","\n","        # serialize model to JSON\n","        print(\"Create json\")\n","        com_model_json = self.combined.to_json()\n","        gen_model_json = self.generator.to_json()\n","        dis_model_json = self.discriminator.to_json()\n","        with open(\"./com_model.json\", \"w\") as json_file:\n","            json_file.write(com_model_json)\n","        with open(\"./gen_model.json\", \"w\") as json_file:\n","            json_file.write(gen_model_json)\n","        with open(\"./dis_model.json\", \"w\") as json_file:\n","            json_file.write(dis_model_json)            \n","        # serialize weights to HDF5\n","        self.combined.save_weights(\"./com_model.h5\")\n","        self.generator.save_weights(\"./gen_model.h5\")\n","        self.discriminator.save_weights(\"./dis_model.h5\")\n","        print(\"Model saved\")\n","\n","    def sample_images(self, epoch, batch_i):\n","        # create model\n","        model = Sequential()\n","        model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n","        model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n","        model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n","        # Compile model\n","        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n","        r, c = 3, 3\n","\n","        imgs_A, imgs_B = self.data_loader.load_data(batch_size=3, is_testing=True)\n","        fake_A = self.generator.predict(imgs_B)\n","\n","        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        titles = ['Condition', 'Generated', 'Original']\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i, j].imshow(gen_imgs[cnt])\n","                axs[i, j].set_title(titles[i])\n","                axs[i, j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n","        plt.close()\n","\n","\n","if __name__ == '__main__':\n","    gan = Pix2Pix()\n","    counts = input('Train : 1\\nTest  : 2\\n : ')\n","    if (int(counts) == 1):\n","        gan.train(epochs=25, batch_size=1, sample_interval=50)\n","    if (int(counts) == 2):\n","        ## use the trained model to generate data\n","        origin_shape = [[0]*3 for i in range(11)] # 10행 3열 행렬 초기화 \n","        test_model = gan.generator\n","        test_model.load_weights(\"./gen_model.h5\")\n","        path = glob(\"./datasets/sample/test/*\")\n","        num = 1\n","        for img in path:\n","            img_B = scipy.misc.imread(img, mode='RGB').astype(np.float)\n","            # m, n, d = img_B.shape\n","            print(img_B.shape)\n","\n","            origin_shape[num][0] = m\n","            origin_shape[num][1] = n\n","            img_B = imresize(img_B, (256, 256, 3))\n","            print(img_B.shape)\n","\n","            m, n, d = img_B.shape\n","            img_show = np.zeros((m, 2 * n, d))\n","            \n","            img_b = np.array([img_B]) / 127.5 - 1\n","            fake_A = 0.5 * (test_model.predict(img_b))[0] + 0.5\n","            \n","            img_show[:, :n, :] = img_B / 255\n","            img_show[:, n:2 * n, :] = fake_A\n","            scipy.misc.imsave(\"./%d.jpg\" % num,img_show)\n","            num = num + 1\n","    \"\"\"\n","    files.download('com_model.json')\n","    files.download('gen_model.json')\n","    files.download('dis_model.json')\n","    files.download('com_model.h5')\n","    files.download('gen_model.h5')\n","    files.download('dis_model.h5')\n","    print(\"finished..\")\n","    \"\"\"\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Train : 1\n","Test  : 2\n"," : 2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:260: DeprecationWarning: `imread` is deprecated!\n","`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imread`` instead.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:266: DeprecationWarning: `imresize` is deprecated!\n","`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``skimage.transform.resize`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["(32, 70, 3)\n","(256, 256, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:277: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["(29, 40, 3)\n","(256, 256, 3)\n","(49, 86, 3)\n","(256, 256, 3)\n","(42, 100, 3)\n","(256, 256, 3)\n","(23, 52, 3)\n","(256, 256, 3)\n","(23, 50, 3)\n","(256, 256, 3)\n","(16, 142, 3)\n","(256, 256, 3)\n","(38, 92, 3)\n","(256, 256, 3)\n","(17, 240, 3)\n","(256, 256, 3)\n","(16, 76, 3)\n","(256, 256, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pC-qPpWEGcVv","colab_type":"text"},"source":["# data_loader.py"]},{"cell_type":"code","metadata":{"id":"-lMeMC65ZC1k","colab_type":"code","colab":{}},"source":["import scipy\n","from glob import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","class DataLoader():\n","    def __init__(self, dataset_name, img_res=(128, 128)):\n","        self.dataset_name = dataset_name\n","        self.img_res = img_res\n","\n","    def load_data(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"test\"\n","        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","\n","        batch_images = np.random.choice(path, size=batch_size)\n","\n","        imgs_A = []\n","        imgs_B = []\n","        for img_path in batch_images:\n","            img = self.imread(img_path)\n","\n","            h, w, _ = img.shape\n","            _w = int(w/2)\n","            img_A, img_B = img[:, :_w, :], img[:, _w:, :]\n","\n","            img_A = scipy.misc.imresize(img_A, self.img_res)\n","            img_B = scipy.misc.imresize(img_B, self.img_res)\n","\n","            # If training => do random flip\n","            if not is_testing and np.random.random() < 0.5:\n","                img_A = np.fliplr(img_A)\n","                img_B = np.fliplr(img_B)\n","\n","            imgs_A.append(img_A)\n","            imgs_B.append(img_B)\n","\n","        imgs_A = np.array(imgs_A)/127.5 - 1.\n","        imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","        return imgs_A, imgs_B\n","\n","    def load_batch(self, batch_size=1, is_testing=False):\n","        data_type = \"train\" if not is_testing else \"val\"\n","        path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n","\n","        self.n_batches = int(len(path) / batch_size)\n","\n","        for i in range(self.n_batches-1):\n","            batch = path[i*batch_size:(i+1)*batch_size]\n","            imgs_A, imgs_B = [], []\n","            for img in batch:\n","                img = self.imread(img)\n","                h, w, _ = img.shape\n","                half_w = int(w/2)\n","                img_A = img[:, :half_w, :]\n","                img_B = img[:, half_w:, :]\n","\n","                img_A = scipy.misc.imresize(img_A, self.img_res)\n","                img_B = scipy.misc.imresize(img_B, self.img_res)\n","\n","                if not is_testing and np.random.random() > 0.5:\n","                        img_A = np.fliplr(img_A)\n","                        img_B = np.fliplr(img_B)\n","\n","                imgs_A.append(img_A)\n","                imgs_B.append(img_B)\n","\n","            imgs_A = np.array(imgs_A)/127.5 - 1.\n","            imgs_B = np.array(imgs_B)/127.5 - 1.\n","\n","            yield imgs_A, imgs_B\n","\n","\n","    def imread(self, path):\n","        return scipy.misc.imread(path, mode='RGB').astype(np.float)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xa4jnc37L6Da","colab_type":"code","outputId":"8be615ce-72b4-409e-87d5-4164bcb80583","executionInfo":{"status":"error","timestamp":1576215839893,"user_tz":-540,"elapsed":7959,"user":{"displayName":"김광륜","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSwcYweAalXduuvjH1r9oJZt8MGaZqh-x0XppU=s64","userId":"15296129808647488288"}},"colab":{"base_uri":"https://localhost:8080/","height":358}},"source":["import socketserver\n","import datetime\n","import base64\n","import numpy as np\n","import cv2\n","!curl ipecho.net/plain\n","\n","class MyTCPHandler(socketserver.BaseRequestHandler):\n","\n","    def handle(self):\n","        print(\"get....\")\n","        image1 = []\n","        try:\n","            while True:\n","                data = self.request.recv(82100)  # 클라이언트가보낸데이터를가져옵니다\n","                print('data,', data)\n","                # data = base64.b64decode(data)\n","                if not data or len(data) == 0:\n","                    break\n","                image1.extend(data)\n","            print(\"get over\")\n","            image = np.asarray(bytearray(image1), dtype=\"uint8\")\n","            # print(\"1\", image)\n","            # print(\"2\",len(image))  39559\n","            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n","            cv2.imwrite(\"./test.jpg\", image)\n","            cv2.namedWindow(\"Image\")\n","            cv2.imshow(\"Image\", image)\n","            cv2.waitKey(0)\n","            cv2.destroyAllWindows()\n","            print(\"받았습니다\")\n","            self.request.sendall(\"get your connet!\".encode(\"utf-8\"))\n","        except Exception:\n","            print(self.client_address, \"연결해제\")\n","        finally:\n","            self.request.close()  # 예외 후 연결을 닫습니다.\n","\n","    # before handle,연결설정：\n","    def setup(self):\n","        now_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","        print(now_time)\n","        print(\"연결설정：\", self.client_address)\n","\n","    # finish run  after handle\n","    def finish(self):\n","        print(\"연결해제\")\n","\n","\n","if __name__ == \"__main__\":\n","    HOST, PORT = \"\", 7777\n","    # server=socketserver.TCPServer((HOST,PORT),MyTCPHandler)  #매개 변수를 전달하는 인스턴스 객체\n","\n","    # 멀티스레드\n","    server = socketserver.ThreadingTCPServer((HOST, PORT), MyTCPHandler)\n","    server.serve_forever()  # 계속연결"],"execution_count":0,"outputs":[{"output_type":"stream","text":["34.69.200.15"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d2ce6f5b9eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# 멀티스레드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocketserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadingTCPServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHOST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyTCPHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 계속연결\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.6/socketserver.py\u001b[0m in \u001b[0;36mserve_forever\u001b[0;34m(self, poll_interval)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                     \u001b[0;31m# bpo-35017: shutdown() called during select(), exit immediately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}